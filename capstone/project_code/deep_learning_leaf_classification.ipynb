{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the training data...\n",
      "Training data loaded!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# If you want to use Theano, all you need to change\n",
    "# is the dim ordering whenever you are dealing with\n",
    "# the image array. Instead of\n",
    "# (samples, rows, cols, channels) it should be\n",
    "# (samples, channels, rows, cols)\n",
    "\n",
    "# Keras stuff\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "# A large amount of the data loading code is based on najeebkhan's kernel\n",
    "# Check it out at https://www.kaggle.com/najeebkhan/leaf-classification/neural-network-through-keras\n",
    "root = ''\n",
    "np.random.seed(2016)\n",
    "split_random_state = 7\n",
    "split = .9\n",
    "\n",
    "\n",
    "def load_numeric_training(standardize=True):\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted features for the training data\n",
    "    and returns a tuple of the image ids, the data, and the labels\n",
    "    \"\"\"\n",
    "    # Read data from the CSV file\n",
    "    data = pd.read_csv(os.path.join(root, 'train.csv'))\n",
    "    ID = data.pop('id')\n",
    "\n",
    "    # Since the labels are textual, so we encode them categorically\n",
    "    y = data.pop('species')\n",
    "    y = LabelEncoder().fit(y).transform(y)\n",
    "    # standardize the data by setting the mean to 0 and std to 1\n",
    "    X = StandardScaler().fit(data).transform(data) if standardize else data.values\n",
    "\n",
    "    return ID, X, y\n",
    "\n",
    "\n",
    "def load_numeric_test(standardize=True):\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted features for the test data\n",
    "    and returns a tuple of the image ids, the data\n",
    "    \"\"\"\n",
    "    test = pd.read_csv(os.path.join(root, 'test.csv'))\n",
    "    ID = test.pop('id')\n",
    "    # standardize the data by setting the mean to 0 and std to 1\n",
    "    test = StandardScaler().fit(test).transform(test) if standardize else test.values\n",
    "    return ID, test\n",
    "\n",
    "\n",
    "def resize_img(img, max_dim=96):\n",
    "    \"\"\"\n",
    "    Resize the image to so the maximum side is of size max_dim\n",
    "    Returns a new image of the right size\n",
    "    \"\"\"\n",
    "    # Get the axis with the larger dimension\n",
    "    max_ax = max((0, 1), key=lambda i: img.size[i])\n",
    "    # Scale both axes so the image's largest dimension is max_dim\n",
    "    scale = max_dim / float(img.size[max_ax])\n",
    "    return img.resize((int(img.size[0] * scale), int(img.size[1] * scale)))\n",
    "\n",
    "\n",
    "def load_image_data(ids, max_dim=96, center=True):\n",
    "    \"\"\"\n",
    "    Takes as input an array of image ids and loads the images as numpy\n",
    "    arrays with the images resized so the longest side is max-dim length.\n",
    "    If center is True, then will place the image in the center of\n",
    "    the output array, otherwise it will be placed at the top-left corner.\n",
    "    \"\"\"\n",
    "    # Initialize the output array\n",
    "    # NOTE: Theano users comment line below and\n",
    "    X = np.empty((len(ids), max_dim, max_dim, 1))\n",
    "    # X = np.empty((len(ids), 1, max_dim, max_dim)) # uncomment this\n",
    "    for i, idee in enumerate(ids):\n",
    "        # Turn the image into an array\n",
    "        x = resize_img(load_img(os.path.join(root, 'images', str(idee) + '.jpg'), grayscale=True), max_dim=max_dim)\n",
    "        x = img_to_array(x)\n",
    "        # Get the corners of the bounding box for the image\n",
    "        # NOTE: Theano users comment the two lines below and\n",
    "        length = x.shape[0]\n",
    "        width = x.shape[1]\n",
    "        # length = x.shape[1] # uncomment this\n",
    "        # width = x.shape[2] # uncomment this\n",
    "        if center:\n",
    "            h1 = int((max_dim - length) / 2)\n",
    "            h2 = h1 + length\n",
    "            w1 = int((max_dim - width) / 2)\n",
    "            w2 = w1 + width\n",
    "        else:\n",
    "            h1, w1 = 0, 0\n",
    "            h2, w2 = (length, width)\n",
    "        # Insert into image matrix\n",
    "        # NOTE: Theano users comment line below and\n",
    "        X[i, h1:h2, w1:w2, 0:1] = x\n",
    "        # X[i, 0:1, h1:h2, w1:w2] = x  # uncomment this\n",
    "    # Scale the array values so they are between 0 and 1\n",
    "    return np.around(X / 255.0)\n",
    "\n",
    "\n",
    "def load_train_data(split=split, random_state=None):\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted feature and image training data and\n",
    "    splits them into training and cross-validation.\n",
    "    Returns one tuple for the training data and one for the validation\n",
    "    data. Each tuple is in the order pre-extracted features, images,\n",
    "    and labels.\n",
    "    \"\"\"\n",
    "    # Load the pre-extracted features\n",
    "    ID, X_num_tr, y = load_numeric_training()\n",
    "    # Load the image data\n",
    "    X_img_tr = load_image_data(ID)\n",
    "    # Split them into validation and cross-validation\n",
    "    sss = StratifiedShuffleSplit(n_splits=1, train_size=split, random_state=random_state)\n",
    "    train_ind, test_ind = next(sss.split(X_num_tr, y))\n",
    "    X_num_val, X_img_val, y_val = X_num_tr[test_ind], X_img_tr[test_ind], y[test_ind]\n",
    "    X_num_tr, X_img_tr, y_tr = X_num_tr[train_ind], X_img_tr[train_ind], y[train_ind]\n",
    "    return (X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val)\n",
    "\n",
    "\n",
    "def load_test_data():\n",
    "    \"\"\"\n",
    "    Loads the pre-extracted feature and image test data.\n",
    "    Returns a tuple in the order ids, pre-extracted features,\n",
    "    and images.\n",
    "    \"\"\"\n",
    "    # Load the pre-extracted features\n",
    "    ID, X_num_te = load_numeric_test()\n",
    "    # Load the image data\n",
    "    X_img_te = load_image_data(ID)\n",
    "    return ID, X_num_te, X_img_te\n",
    "\n",
    "print('Loading the training data...')\n",
    "(X_num_tr, X_img_tr, y_tr), (X_num_val, X_img_val, y_val) = load_train_data(random_state=split_random_state)\n",
    "y_tr_cat = to_categorical(y_tr)\n",
    "y_val_cat = to_categorical(y_val)\n",
    "print('Training data loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Data Augmenter...\n",
      "Finished making data augmenter...\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator, NumpyArrayIterator, array_to_img\n",
    "\n",
    "# A little hacky piece of code to get access to the indices of the images\n",
    "# the data augmenter is working with.\n",
    "class ImageDataGenerator2(ImageDataGenerator):\n",
    "    def flow(self, X, y=None, batch_size=32, shuffle=True, seed=None,\n",
    "             save_to_dir=None, save_prefix='', save_format='jpeg'):\n",
    "        return NumpyArrayIterator2(\n",
    "            X, y, self,\n",
    "            batch_size=batch_size, shuffle=shuffle, seed=seed,\n",
    "            dim_ordering=self.dim_ordering,\n",
    "            save_to_dir=save_to_dir, save_prefix=save_prefix, save_format=save_format)\n",
    "\n",
    "\n",
    "class NumpyArrayIterator2(NumpyArrayIterator):\n",
    "    def next(self):\n",
    "        # for python 2.x.\n",
    "        # Keeps under lock only the mechanism which advances\n",
    "        # the indexing of each batch\n",
    "        # see http://anandology.com/blog/using-iterators-and-generators/\n",
    "        with self.lock:\n",
    "            # We changed index_array to self.index_array\n",
    "            self.index_array, current_index, current_batch_size = next(self.index_generator)\n",
    "        # The transformation of images is not under thread lock so it can be done in parallel\n",
    "        batch_x = np.zeros(tuple([current_batch_size] + list(self.x.shape)[1:]))\n",
    "        for i, j in enumerate(self.index_array):\n",
    "            x = self.x[j]\n",
    "            x = self.image_data_generator.random_transform(x.astype('float32'))\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "        if self.save_to_dir:\n",
    "            for i in range(current_batch_size):\n",
    "                img = array_to_img(batch_x[i], self.dim_ordering, scale=True)\n",
    "                fname = '{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix,\n",
    "                                                                  index=current_index + i,\n",
    "                                                                  hash=np.random.randint(1e4),\n",
    "                                                                  format=self.save_format)\n",
    "                img.save(os.path.join(self.save_to_dir, fname))\n",
    "        if self.y is None:\n",
    "            return batch_x\n",
    "        batch_y = self.y[self.index_array]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "print('Creating Data Augmenter...')\n",
    "imgen = ImageDataGenerator2(\n",
    "    rotation_range=20,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    fill_mode='nearest')\n",
    "imgen_train = imgen.flow(X_img_tr, y_tr_cat, seed=np.random.randint(1, 10000))\n",
    "print('Finished making data augmenter...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating the model...\n",
      "Model created!\n",
      "Training model...\n",
      "Epoch 00000: val_loss improved from inf to 3.50950, saving model to leafnet.h5\n",
      "Epoch 00001: val_loss improved from 3.50950 to 2.33360, saving model to leafnet.h5\n",
      "Epoch 00002: val_loss improved from 2.33360 to 1.52753, saving model to leafnet.h5\n",
      "Epoch 00003: val_loss improved from 1.52753 to 1.01563, saving model to leafnet.h5\n",
      "Epoch 00004: val_loss improved from 1.01563 to 0.74639, saving model to leafnet.h5\n",
      "Epoch 00005: val_loss improved from 0.74639 to 0.49833, saving model to leafnet.h5\n",
      "Epoch 00006: val_loss improved from 0.49833 to 0.36759, saving model to leafnet.h5\n",
      "Epoch 00007: val_loss improved from 0.36759 to 0.27797, saving model to leafnet.h5\n",
      "Epoch 00008: val_loss improved from 0.27797 to 0.20429, saving model to leafnet.h5\n",
      "Epoch 00009: val_loss improved from 0.20429 to 0.16155, saving model to leafnet.h5\n",
      "Epoch 00010: val_loss improved from 0.16155 to 0.10853, saving model to leafnet.h5\n",
      "Epoch 00011: val_loss did not improve\n",
      "Epoch 00012: val_loss improved from 0.10853 to 0.08459, saving model to leafnet.h5\n",
      "Epoch 00013: val_loss improved from 0.08459 to 0.07341, saving model to leafnet.h5\n",
      "Epoch 00014: val_loss improved from 0.07341 to 0.05941, saving model to leafnet.h5\n",
      "Epoch 00015: val_loss improved from 0.05941 to 0.05532, saving model to leafnet.h5\n",
      "Epoch 00016: val_loss improved from 0.05532 to 0.04488, saving model to leafnet.h5\n",
      "Epoch 00017: val_loss improved from 0.04488 to 0.03780, saving model to leafnet.h5\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 00019: val_loss improved from 0.03780 to 0.03758, saving model to leafnet.h5\n",
      "Epoch 00020: val_loss did not improve\n",
      "Epoch 00021: val_loss improved from 0.03758 to 0.02198, saving model to leafnet.h5\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 00023: val_loss improved from 0.02198 to 0.02041, saving model to leafnet.h5\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 00025: val_loss did not improve\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 00028: val_loss did not improve\n",
      "Epoch 00029: val_loss improved from 0.02041 to 0.01791, saving model to leafnet.h5\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 00031: val_loss improved from 0.01791 to 0.01707, saving model to leafnet.h5\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 00033: val_loss improved from 0.01707 to 0.01653, saving model to leafnet.h5\n",
      "Epoch 00034: val_loss improved from 0.01653 to 0.01171, saving model to leafnet.h5\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 00036: val_loss improved from 0.01171 to 0.00710, saving model to leafnet.h5\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 00042: val_loss did not improve\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 00044: val_loss improved from 0.00710 to 0.00516, saving model to leafnet.h5\n",
      "Epoch 00045: val_loss improved from 0.00516 to 0.00433, saving model to leafnet.h5\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 00049: val_loss did not improve\n",
      "Epoch 00050: val_loss did not improve\n",
      "Epoch 00051: val_loss did not improve\n",
      "Epoch 00052: val_loss did not improve\n",
      "Epoch 00053: val_loss did not improve\n",
      "Epoch 00054: val_loss did not improve\n",
      "Epoch 00055: val_loss improved from 0.00433 to 0.00402, saving model to leafnet.h5\n",
      "Epoch 00056: val_loss did not improve\n",
      "Epoch 00057: val_loss did not improve\n",
      "Epoch 00058: val_loss did not improve\n",
      "Epoch 00059: val_loss did not improve\n",
      "Epoch 00060: val_loss did not improve\n",
      "Epoch 00061: val_loss did not improve\n",
      "Epoch 00062: val_loss did not improve\n",
      "Epoch 00063: val_loss did not improve\n",
      "Epoch 00064: val_loss improved from 0.00402 to 0.00294, saving model to leafnet.h5\n",
      "Epoch 00065: val_loss did not improve\n",
      "Epoch 00066: val_loss improved from 0.00294 to 0.00284, saving model to leafnet.h5\n",
      "Epoch 00067: val_loss did not improve\n",
      "Epoch 00068: val_loss improved from 0.00284 to 0.00232, saving model to leafnet.h5\n",
      "Epoch 00069: val_loss did not improve\n",
      "Epoch 00070: val_loss improved from 0.00232 to 0.00230, saving model to leafnet.h5\n",
      "Epoch 00071: val_loss improved from 0.00230 to 0.00151, saving model to leafnet.h5\n",
      "Epoch 00072: val_loss did not improve\n",
      "Epoch 00073: val_loss did not improve\n",
      "Epoch 00074: val_loss did not improve\n",
      "Epoch 00075: val_loss did not improve\n",
      "Epoch 00076: val_loss improved from 0.00151 to 0.00149, saving model to leafnet.h5\n",
      "Epoch 00077: val_loss did not improve\n",
      "Epoch 00078: val_loss did not improve\n",
      "Epoch 00079: val_loss did not improve\n",
      "Epoch 00080: val_loss did not improve\n",
      "Epoch 00081: val_loss did not improve\n",
      "Epoch 00082: val_loss did not improve\n",
      "Epoch 00083: val_loss did not improve\n",
      "Epoch 00084: val_loss did not improve\n",
      "Epoch 00085: val_loss did not improve\n",
      "Epoch 00086: val_loss did not improve\n",
      "Epoch 00087: val_loss did not improve\n",
      "Epoch 00088: val_loss did not improve\n",
      "Loading the best model...\n",
      "Best Model loaded!\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Convolution2D, MaxPooling2D, Flatten, Input, merge\n",
    "\n",
    "\n",
    "def combined_model():\n",
    "\n",
    "    # Define the image input\n",
    "    image = Input(shape=(96, 96, 1), name='image')\n",
    "    # Pass it through the first convolutional layer\n",
    "    x = Convolution2D(12, 5, 5, input_shape=(96, 96, 1), border_mode='same')(image)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    # Now through the second convolutional layer\n",
    "    x = (Convolution2D(42, 5, 5, border_mode='same'))(x)\n",
    "    x = (Activation('relu'))(x)\n",
    "    x = (MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))(x)\n",
    "\n",
    "    # Flatten our array\n",
    "    x = Flatten()(x)\n",
    "    # Define the pre-extracted feature input\n",
    "    numerical = Input(shape=(192,), name='numerical')\n",
    "    # Concatenate the output of our convnet with our pre-extracted feature input\n",
    "    concatenated = merge([x, numerical], mode='concat')\n",
    "\n",
    "    # Add a fully connected layer just like in a normal MLP\n",
    "    x = Dense(100, activation='relu')(concatenated)\n",
    "    x = Dropout(.5)(x)\n",
    "\n",
    "    # Get the final output\n",
    "    out = Dense(99, activation='softmax')(x)\n",
    "    # How we create models with the Functional API\n",
    "    model = Model(input=[image, numerical], output=out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "print('Creating the model...')\n",
    "model = combined_model()\n",
    "print('Model created!')\n",
    "\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "def combined_generator(imgen, X):\n",
    "    \"\"\"\n",
    "    A generator to train our keras neural network. It\n",
    "    takes the image augmenter generator and the array\n",
    "    of the pre-extracted features.\n",
    "    It yields a minibatch and will run indefinitely\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        for i in range(X.shape[0]):\n",
    "            # Get the image batch and labels\n",
    "            batch_img, batch_y = next(imgen)\n",
    "            # This is where that change to the source code we\n",
    "            # made will come in handy. We can now access the indicies\n",
    "            # of the images that imgen gave us.\n",
    "            x = X[imgen.index_array]\n",
    "            yield [batch_img, x], batch_y\n",
    "\n",
    "# autosave best Model\n",
    "best_model_file = \"leafnet.h5\"\n",
    "best_model = ModelCheckpoint(best_model_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "\n",
    "print('Training model...')\n",
    "history = model.fit_generator(combined_generator(imgen_train, X_num_tr),\n",
    "                              samples_per_epoch=X_num_tr.shape[0],\n",
    "                              nb_epoch=89,\n",
    "                              validation_data=([X_img_val, X_num_val], y_val_cat),\n",
    "                              nb_val_samples=X_num_val.shape[0],\n",
    "                              verbose=0,\n",
    "                              callbacks=[best_model])\n",
    "\n",
    "print('Loading the best model...')\n",
    "model = load_model(best_model_file)\n",
    "print('Best Model loaded!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating and writing submission...\n",
      "Finished writing submission\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Acer_Capillipes</th>\n",
       "      <th>Acer_Circinatum</th>\n",
       "      <th>Acer_Mono</th>\n",
       "      <th>Acer_Opalus</th>\n",
       "      <th>Acer_Palmatum</th>\n",
       "      <th>Acer_Pictum</th>\n",
       "      <th>Acer_Platanoids</th>\n",
       "      <th>Acer_Rubrum</th>\n",
       "      <th>Acer_Rufinerve</th>\n",
       "      <th>Acer_Saccharinum</th>\n",
       "      <th>...</th>\n",
       "      <th>Salix_Fragilis</th>\n",
       "      <th>Salix_Intergra</th>\n",
       "      <th>Sorbus_Aria</th>\n",
       "      <th>Tilia_Oliveri</th>\n",
       "      <th>Tilia_Platyphyllos</th>\n",
       "      <th>Tilia_Tomentosa</th>\n",
       "      <th>Ulmus_Bergmanniana</th>\n",
       "      <th>Viburnum_Tinus</th>\n",
       "      <th>Viburnum_x_Rhytidophylloides</th>\n",
       "      <th>Zelkova_Serrata</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1576</th>\n",
       "      <td>6.828971e-12</td>\n",
       "      <td>9.999554e-01</td>\n",
       "      <td>2.532231e-12</td>\n",
       "      <td>2.505395e-12</td>\n",
       "      <td>4.421139e-05</td>\n",
       "      <td>4.795865e-11</td>\n",
       "      <td>5.379234e-15</td>\n",
       "      <td>1.758586e-10</td>\n",
       "      <td>1.710379e-09</td>\n",
       "      <td>6.897322e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>7.976994e-16</td>\n",
       "      <td>1.950241e-18</td>\n",
       "      <td>2.244144e-15</td>\n",
       "      <td>2.998040e-15</td>\n",
       "      <td>4.235128e-16</td>\n",
       "      <td>7.315933e-11</td>\n",
       "      <td>3.680398e-13</td>\n",
       "      <td>1.624939e-17</td>\n",
       "      <td>3.678837e-18</td>\n",
       "      <td>2.738374e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>2.513535e-10</td>\n",
       "      <td>5.193966e-13</td>\n",
       "      <td>2.628697e-17</td>\n",
       "      <td>4.540522e-07</td>\n",
       "      <td>1.132070e-15</td>\n",
       "      <td>1.421895e-16</td>\n",
       "      <td>3.547827e-16</td>\n",
       "      <td>9.070637e-09</td>\n",
       "      <td>1.569394e-06</td>\n",
       "      <td>9.290154e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>9.558155e-14</td>\n",
       "      <td>1.371461e-16</td>\n",
       "      <td>5.898750e-06</td>\n",
       "      <td>1.871302e-11</td>\n",
       "      <td>2.807346e-07</td>\n",
       "      <td>1.822619e-07</td>\n",
       "      <td>1.483069e-13</td>\n",
       "      <td>7.977670e-11</td>\n",
       "      <td>1.720036e-14</td>\n",
       "      <td>7.032176e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1579</th>\n",
       "      <td>2.333070e-08</td>\n",
       "      <td>4.281010e-12</td>\n",
       "      <td>6.705611e-15</td>\n",
       "      <td>3.664056e-15</td>\n",
       "      <td>3.434385e-10</td>\n",
       "      <td>4.807554e-08</td>\n",
       "      <td>1.559671e-16</td>\n",
       "      <td>3.730022e-11</td>\n",
       "      <td>1.343821e-11</td>\n",
       "      <td>2.394507e-10</td>\n",
       "      <td>...</td>\n",
       "      <td>3.288160e-16</td>\n",
       "      <td>2.925642e-17</td>\n",
       "      <td>5.221805e-12</td>\n",
       "      <td>3.290714e-12</td>\n",
       "      <td>4.291854e-11</td>\n",
       "      <td>2.401864e-16</td>\n",
       "      <td>2.836099e-14</td>\n",
       "      <td>1.846274e-14</td>\n",
       "      <td>2.798262e-13</td>\n",
       "      <td>5.507949e-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1580</th>\n",
       "      <td>2.258098e-13</td>\n",
       "      <td>7.454951e-12</td>\n",
       "      <td>7.070667e-09</td>\n",
       "      <td>7.872297e-09</td>\n",
       "      <td>7.771679e-10</td>\n",
       "      <td>1.096963e-14</td>\n",
       "      <td>1.788917e-10</td>\n",
       "      <td>9.525122e-08</td>\n",
       "      <td>9.287893e-12</td>\n",
       "      <td>3.137879e-15</td>\n",
       "      <td>...</td>\n",
       "      <td>2.753404e-12</td>\n",
       "      <td>1.445661e-11</td>\n",
       "      <td>4.039766e-15</td>\n",
       "      <td>1.378845e-07</td>\n",
       "      <td>1.544177e-13</td>\n",
       "      <td>1.354596e-11</td>\n",
       "      <td>3.384666e-12</td>\n",
       "      <td>4.572680e-08</td>\n",
       "      <td>3.506780e-18</td>\n",
       "      <td>1.537113e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1583</th>\n",
       "      <td>1.174118e-18</td>\n",
       "      <td>8.516406e-15</td>\n",
       "      <td>1.515847e-13</td>\n",
       "      <td>5.188471e-14</td>\n",
       "      <td>9.042845e-13</td>\n",
       "      <td>2.265993e-09</td>\n",
       "      <td>2.497719e-12</td>\n",
       "      <td>1.813317e-14</td>\n",
       "      <td>2.941238e-15</td>\n",
       "      <td>1.553611e-16</td>\n",
       "      <td>...</td>\n",
       "      <td>2.213144e-12</td>\n",
       "      <td>5.409478e-14</td>\n",
       "      <td>1.273970e-15</td>\n",
       "      <td>3.742281e-13</td>\n",
       "      <td>3.592727e-15</td>\n",
       "      <td>8.199467e-14</td>\n",
       "      <td>3.151431e-17</td>\n",
       "      <td>3.743032e-16</td>\n",
       "      <td>8.918611e-16</td>\n",
       "      <td>1.579331e-14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Acer_Capillipes  Acer_Circinatum     Acer_Mono   Acer_Opalus  \\\n",
       "id                                                                   \n",
       "1576     6.828971e-12     9.999554e-01  2.532231e-12  2.505395e-12   \n",
       "1577     2.513535e-10     5.193966e-13  2.628697e-17  4.540522e-07   \n",
       "1579     2.333070e-08     4.281010e-12  6.705611e-15  3.664056e-15   \n",
       "1580     2.258098e-13     7.454951e-12  7.070667e-09  7.872297e-09   \n",
       "1583     1.174118e-18     8.516406e-15  1.515847e-13  5.188471e-14   \n",
       "\n",
       "      Acer_Palmatum   Acer_Pictum  Acer_Platanoids   Acer_Rubrum  \\\n",
       "id                                                                 \n",
       "1576   4.421139e-05  4.795865e-11     5.379234e-15  1.758586e-10   \n",
       "1577   1.132070e-15  1.421895e-16     3.547827e-16  9.070637e-09   \n",
       "1579   3.434385e-10  4.807554e-08     1.559671e-16  3.730022e-11   \n",
       "1580   7.771679e-10  1.096963e-14     1.788917e-10  9.525122e-08   \n",
       "1583   9.042845e-13  2.265993e-09     2.497719e-12  1.813317e-14   \n",
       "\n",
       "      Acer_Rufinerve  Acer_Saccharinum       ...         Salix_Fragilis  \\\n",
       "id                                           ...                          \n",
       "1576    1.710379e-09      6.897322e-10       ...           7.976994e-16   \n",
       "1577    1.569394e-06      9.290154e-16       ...           9.558155e-14   \n",
       "1579    1.343821e-11      2.394507e-10       ...           3.288160e-16   \n",
       "1580    9.287893e-12      3.137879e-15       ...           2.753404e-12   \n",
       "1583    2.941238e-15      1.553611e-16       ...           2.213144e-12   \n",
       "\n",
       "      Salix_Intergra   Sorbus_Aria  Tilia_Oliveri  Tilia_Platyphyllos  \\\n",
       "id                                                                      \n",
       "1576    1.950241e-18  2.244144e-15   2.998040e-15        4.235128e-16   \n",
       "1577    1.371461e-16  5.898750e-06   1.871302e-11        2.807346e-07   \n",
       "1579    2.925642e-17  5.221805e-12   3.290714e-12        4.291854e-11   \n",
       "1580    1.445661e-11  4.039766e-15   1.378845e-07        1.544177e-13   \n",
       "1583    5.409478e-14  1.273970e-15   3.742281e-13        3.592727e-15   \n",
       "\n",
       "      Tilia_Tomentosa  Ulmus_Bergmanniana  Viburnum_Tinus  \\\n",
       "id                                                          \n",
       "1576     7.315933e-11        3.680398e-13    1.624939e-17   \n",
       "1577     1.822619e-07        1.483069e-13    7.977670e-11   \n",
       "1579     2.401864e-16        2.836099e-14    1.846274e-14   \n",
       "1580     1.354596e-11        3.384666e-12    4.572680e-08   \n",
       "1583     8.199467e-14        3.151431e-17    3.743032e-16   \n",
       "\n",
       "      Viburnum_x_Rhytidophylloides  Zelkova_Serrata  \n",
       "id                                                   \n",
       "1576                  3.678837e-18     2.738374e-10  \n",
       "1577                  1.720036e-14     7.032176e-11  \n",
       "1579                  2.798262e-13     5.507949e-11  \n",
       "1580                  3.506780e-18     1.537113e-13  \n",
       "1583                  8.918611e-16     1.579331e-14  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the names of the column headers\n",
    "LABELS = sorted(pd.read_csv(os.path.join(root, 'train.csv')).species.unique())\n",
    "\n",
    "index, test, X_img_te = load_test_data()\n",
    "\n",
    "yPred_proba = model.predict([X_img_te, test])\n",
    "\n",
    "# Converting the test predictions in a dataframe as depicted by sample submission\n",
    "yPred = pd.DataFrame(yPred_proba,index=index,columns=LABELS)\n",
    "\n",
    "print('Creating and writing submission...')\n",
    "fp = open('deeplearning_submission2.csv', 'w')\n",
    "fp.write(yPred.to_csv())\n",
    "print('Finished writing submission')\n",
    "# Display the submission\n",
    "yPred.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
